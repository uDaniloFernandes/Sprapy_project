# üï∑Ô∏è Projeto de Extra√ß√£o de Dados do SISAB com Scrapy (API S√≠ncrona)

## 1. Resumo üéØ

Este projeto utiliza o framework Scrapy (Python) para automatizar a extra√ß√£o de relat√≥rios de produ√ß√£o do portal SISAB. A solu√ß√£o √© exposta atrav√©s de uma API s√≠ncrona constru√≠da com FastAPI, que permite a um usu√°rio obter as datas dispon√≠veis e solicitar um relat√≥rio diretamente.

O fluxo de trabalho √© direto: uma rota para consultar as datas e outra para receber as datas escolhidas e retornar o arquivo CSV na mesma requisi√ß√£o.

## 2. Arquitetura do Projeto üèóÔ∏è

O projeto √© composto por dois componentes principais que trabalham juntos:

### 2.1. Spiders (Scrapy)

-   **`DateFinderSpider` (`get_dates.py`):** Um spider simples cuja √∫nica fun√ß√£o √© acessar o portal do SISAB e extrair a lista de todas as compet√™ncias (datas) dispon√≠veis para consulta.
-   **`SisabSpider` (`sisab.py`):** O spider principal que realiza a extra√ß√£o. Ele √© projetado para receber uma lista de datas e um caminho de arquivo como par√¢metros, executar a extra√ß√£o completa e salvar o resultado no local especificado.

### 2.2. API (FastAPI)

A API (`main.py`) serve como a interface p√∫blica para o sistema. Ela orquestra a execu√ß√£o dos spiders de forma s√≠ncrona (bloqueante) para responder diretamente √†s requisi√ß√µes do usu√°rio.

## 3. API S√≠ncrona (FastAPI) ‚ö°

A API possui duas rotas principais que definem o fluxo de trabalho.

### ‚ö†Ô∏è Aviso Cr√≠tico sobre Timeouts

A rota `/iniciar-extracao` executa todo o processo de web scraping (que pode levar v√°rios minutos) e s√≥ ent√£o retorna o arquivo. Plataformas de nuvem como o Render imp√µem um **limite de tempo (timeout)** para requisi√ß√µes HTTP (geralmente 30-60 segundos).

**Se a sua extra√ß√£o demorar mais do que esse limite, a conex√£o ser√° cortada e o download falhar√° com um erro de timeout.** Esta arquitetura √© ideal para extra√ß√µes r√°pidas ou para uso em ambiente local. Para extra√ß√µes longas em produ√ß√£o, uma arquitetura ass√≠ncrona (com tarefas em segundo plano) √© recomendada.

### L√≥gica das Rotas

-   #### `GET /date-finder`
    -   **Fun√ß√£o:** Retorna a lista de datas dispon√≠veis no SISAB.
    -   **L√≥gica:** A API executa o `DateFinderSpider`, espera sua conclus√£o, coleta o resultado e o retorna como um array JSON.

-   #### `POST /iniciar-extracao`
    -   **Fun√ß√£o:** Gera e retorna um relat√≥rio diretamente.
    -   **L√≥gica:** Recebe um array de datas no corpo da requisi√ß√£o. A API ent√£o executa o `SisabSpider`, passando as datas escolhidas. O spider salva o resultado em um arquivo tempor√°rio no servidor, e a API retorna esse arquivo diretamente para o usu√°rio como um download na mesma requisi√ß√£o.

## 4. Como Executar üöÄ

No terminal, navegue at√© a pasta `api_service` e execute:

```sh
uvicorn main:app --reload
```

A API estar√° dispon√≠vel em `http://127.0.0.1:8000`. A documenta√ß√£o interativa, onde voc√™ pode testar as rotas, pode ser acessada em `http://127.0.0.1:8000/docs`.

## 5. Fluxo de Trabalho üîÑ

1.  **Obter as Datas:** Acesse a documenta√ß√£o (`/docs`) e execute a rota `GET /date-finder`. Voc√™ receber√° uma lista de todas as datas dispon√≠veis, como `["202405", "202404", ...]`. 

2.  **Gerar o Relat√≥rio:**
    -   V√° para a rota `POST /iniciar-extracao` na documenta√ß√£o.
    -   Clique em "Try it out".
    -   No campo "Request body", insira um array JSON com as datas que voc√™ deseja extrair. Exemplo:
        ```json
        [
          "202405",
          "202404"
        ]
        ```
    -   Clique em "Execute".
    -   **Aguarde.** A requisi√ß√£o ficar√° pendente enquanto o Scrapy trabalha. Quando a extra√ß√£o terminar, o download do arquivo `Relatorio-SISAB.csv` come√ßar√° automaticamente no seu navegador.

## 6. Configura√ß√£o ‚öôÔ∏è

As principais configura√ß√µes de extra√ß√£o (como estados, tipos de equipe, etc.) s√£o feitas diretamente no dicion√°rio `form_data` dentro do arquivo `Scrapy_project/spiders/sisab.py`.
